{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c97b2e20-59b7-4eef-8853-bd7b36eb7855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "907f9aba-83b4-4cc3-8014-0b26967a39af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b57c3ff-270c-4e43-b192-a51d2f52984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_cheque_image(cheque_image_path, desired_width=1500, clip_limit=0.3, tile_grid_size=(2, 2), gaussian_kernel=(3, 3), gaussian_std=0, adaptive_threshold=False, erosion_dilation=False):\n",
    "    # Load the cheque image without resizing\n",
    "    image = cv2.imread(cheque_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Could not load the image.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate the aspect ratio\n",
    "    aspect_ratio = image.shape[1] / image.shape[0]\n",
    "\n",
    "    # Calculate the corresponding height to maintain the aspect ratio\n",
    "    desired_height = int(desired_width / aspect_ratio)\n",
    "\n",
    "    # Resize the image to the desired dimensions\n",
    "    resized_image = cv2.resize(image, (desired_width, desired_height))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Remove shadows using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    shadow_removal_image = clahe.apply(gray_image)\n",
    "\n",
    "    # Apply Gaussian blur for noise reduction\n",
    "    blurred_image = cv2.GaussianBlur(shadow_removal_image, gaussian_kernel, gaussian_std)\n",
    "\n",
    "    # Apply morphological operations (erosion and dilation) if enabled\n",
    "    if erosion_dilation:\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        morph_image = cv2.morphologyEx(blurred_image, cv2.MORPH_CLOSE, kernel)\n",
    "        return morph_image\n",
    "\n",
    "    return blurred_image\n",
    "\n",
    "# Path to your cheque image\n",
    "cheque_image_path = \"C:\\\\Users\\\\yashp\\\\OneDrive\\\\Desktop\\\\300\\\\f1.tif\"\n",
    "\n",
    "# Preprocess the cheque image with morphological operations (erosion and dilation)\n",
    "preprocessed_image = preprocess_cheque_image(cheque_image_path, desired_width=1500, clip_limit=0.3, tile_grid_size=(2, 2), gaussian_kernel=(3, 3), gaussian_std=0, adaptive_threshold=False, erosion_dilation=True)\n",
    "\n",
    "if preprocessed_image is not None:\n",
    "    # Display the preprocessed image with morphological operations\n",
    "    cv2.imshow(\"Preprocessed Image with Morphological Operations\", preprocessed_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d410f78-2650-4c51-ac53-2b6ea54cb2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFS Code: ICIC0006308\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Load the cheque image using Pillow (PIL)\n",
    "cheque_image = Image.open(\"C:\\\\Users\\\\yashp\\\\OneDrive\\\\Desktop\\\\300\\\\f20.tif\")\n",
    "\n",
    "# Perform OCR to extract text\n",
    "text = pytesseract.image_to_string(cheque_image)\n",
    "\n",
    "# Split the extracted text by space to find individual words\n",
    "words = text.split()\n",
    "\n",
    "ifs_code = None\n",
    "\n",
    "# Search for a word that matches the pattern of IFS code (typically 11 characters)\n",
    "for word in words:\n",
    "    if len(word) == 11 and word.isalnum():\n",
    "        ifs_code = word\n",
    "        break\n",
    "# Print the extracted IFS code and account number\n",
    "if ifs_code:\n",
    "    print(\"IFS Code:\", ifs_code)\n",
    "else:\n",
    "    print(\"IFS Code not found in the image\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41921207-c098-444f-a9ea-6e3ae8aab845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11010049001545\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Load the cheque image\n",
    "cheque_image = cv2.imread(\"C:\\\\Users\\\\yashp\\\\OneDrive\\\\Desktop\\\\300\\\\f25.tif\")\n",
    "\n",
    "# Define the coordinates for the ROI (top-left and bottom-right points)\n",
    "x1, y1 = 400, 500  # Coordinates of the top-left corner of the ROI\n",
    "x2, y2 = 1200, 600  # Coordinates of the bottom-right corner of the ROI\n",
    "\n",
    "# Crop the image to the specified ROI\n",
    "roi = cheque_image[y1:y2, x1:x2]\n",
    "\n",
    "# Convert the ROI to grayscale\n",
    "gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to make the text more prominent\n",
    "_, thresh = cv2.threshold(gray_roi, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display the segmented image\n",
    "cv2.imshow(\"Segmented Image\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Use Tesseract OCR to extract text from the thresholded image\n",
    "account_number = pytesseract.image_to_string(thresh)\n",
    "\n",
    "# Filter out non-numeric characters\n",
    "filtered_account_number = ''.join(filter(str.isdigit, account_number))\n",
    "\n",
    "# Print the extracted A/C NO.\n",
    "print(filtered_account_number.strip())  # Use strip() to remove leading/trailing whitespace\n",
    "\n",
    "# You can save this account number or use it as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26e72726-a247-4f13-8ac7-cd025008d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€”\n",
      "\n",
      "Plaaca ciqn ahove\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the cheque image\n",
    "cheque_image = cv2.imread(\"C:\\\\Users\\\\yashp\\\\OneDrive\\\\Desktop\\\\300\\\\f20.tif\")\n",
    "\n",
    "# Define the coordinates for the ROI (top-left and bottom-right points)\n",
    "x1, y1 = 1900, 750  # Coordinates of the top-left corner of the ROI\n",
    "x2, y2 = 2300, 900  # Coordinates of the bottom-right corner of the ROI\n",
    "\n",
    "# Crop the image to the specified ROI\n",
    "roi = cheque_image[y1:y2, x1:x2]\n",
    "\n",
    "# Display or save the cropped ROI\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# If you want to save the ROI as a new image:\n",
    "cv2.imwrite(\"cropped_roi.png\", roi)\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Load the cropped ROI\n",
    "roi = cv2.imread(\"cropped_roi.png\")\n",
    "\n",
    "# Convert the ROI to grayscale\n",
    "\n",
    "gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use Tesseract OCR to extract text from the ROI\n",
    "account_number = pytesseract.image_to_string(gray_roi)\n",
    "\n",
    "# Print the extracted A/C NO.\n",
    "print(account_number.strip())  # Use strip() to remove leading/trailing whitespace\n",
    "\n",
    "# You can save this account number or use it as needed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4526ca5-743e-4ea3-a950-6385b633b36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the cheque image\n",
    "cheque_image = cv2.imread(\"C:\\\\Users\\\\yashp\\\\Downloads\\\\300\\\\Cheque 309151.tif\")\n",
    "\n",
    "# Define the coordinates for the ROI (top-left and bottom-right points)\n",
    "x1, y1 = 1900, 650  # Coordinates of the top-left corner of the ROI\n",
    "x2, y2 = 2300, 900  # Coordinates of the bottom-right corner of the ROI\n",
    "\n",
    "# Crop the image to the specified ROI\n",
    "roi = cheque_image[y1:y2, x1:x2]\n",
    "\n",
    "# Display or save the cropped ROI\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# If you want to save the ROI as a new image:\n",
    "cv2.imwrite(\"cropped_roi.png\", roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bde2a7-69ea-401e-b0b9-e79ff8185485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels: {'g', 'f'}\n",
      "Accuracy: 63.64%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Function to extract and preprocess the signature from a cheque image\n",
    "def extract_and_process_signature(image_path, target_length=1000):\n",
    "    # Load the cheque image\n",
    "    cheque_image = cv2.imread(image_path)\n",
    "\n",
    "    # Define the coordinates for the ROI (top-left and bottom-right points)\n",
    "    x1, y1 = 1900, 650  # Coordinates of the top-left corner of the ROI\n",
    "    x2, y2 = 2300, 900  # Coordinates of the bottom-right corner of the ROI\n",
    "\n",
    "    # Crop the image to the specified ROI\n",
    "    signature_segment = cheque_image[y1:y2, x1:x2]\n",
    "\n",
    "    # Your existing code for signature preprocessing goes here\n",
    "    # ...\n",
    "\n",
    "    # After segmentation, apply the SIFT algorithm for feature extraction\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(signature_segment, None)\n",
    "\n",
    "    # Flatten the feature descriptors into a 1D array\n",
    "    signature_features = des.flatten()\n",
    "\n",
    "    # Pad or truncate the array to the target length\n",
    "    signature_features = signature_features[:target_length]\n",
    "\n",
    "    # Return the processed features\n",
    "    return signature_features\n",
    "\n",
    "# Folder containing cheque images\n",
    "cheque_folder = \"C:\\\\Users\\\\yashp\\\\OneDrive\\\\Desktop\\\\300\"\n",
    "\n",
    "# Lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through cheque images in the folder\n",
    "for filename in os.listdir(cheque_folder):\n",
    "    if filename.endswith(\".tif\") or filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(cheque_folder, filename)\n",
    "\n",
    "        # Extract and preprocess the signature\n",
    "        signature_features = extract_and_process_signature(image_path)\n",
    "\n",
    "        # Append features and label (genuine or forged) to the lists\n",
    "        features.append(signature_features)\n",
    "        labels.append(\"g\" if \"g\" in filename else \"f\")\n",
    "\n",
    "# Print unique labels to check the classes\n",
    "print(\"Unique Labels:\", set(labels))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "classifier = svm.SVC()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "101d1df5-b161-4ebb-bbdf-4753ce08ad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashp\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([33099,  2056, 54651,  5216,  3857, 20989, 35658, 46708, 16330,\\n            24246,\\n            ...\\n            37384,  9307, 14430,  5617, 50757,  2960, 27017, 29669,  8217,\\n            24750],\\n           dtype='int64', length=60000)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y[:\u001b[38;5;241m60000\u001b[39m], y[\u001b[38;5;241m6000\u001b[39m:\u001b[38;5;241m70000\u001b[39m]\n\u001b[0;32m     23\u001b[0m shuffle_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;241m60000\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mshuffle_index\u001b[49m\u001b[43m]\u001b[49m, y_train[shuffle_index]  \u001b[38;5;66;03m# Fixed the shuffle syntax\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Creating a 2-detector\u001b[39;00m\n\u001b[0;32m     27\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint8)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([33099,  2056, 54651,  5216,  3857, 20989, 35658, 46708, 16330,\\n            24246,\\n            ...\\n            37384,  9307, 14430,  5617, 50757,  2960, 27017, 29669,  8217,\\n            24750],\\n           dtype='int64', length=60000)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# fetching dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "x, y = mnist['data'], mnist['target']\n",
    "\n",
    "some_digit = x.to_numpy()[36001]\n",
    "some_digit_image = some_digit.reshape(28, 28)  # let's reshape to plot it\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary,\n",
    "           interpolation='nearest')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "x_train, x_test = x[:60000], x[6000:70000]\n",
    "y_train, y_test = y[:60000], y[6000:70000]\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "x_train, y_train = x_train[shuffle_index], y_train[shuffle_index]  # Fixed the shuffle syntax\n",
    "\n",
    "# Creating a 2-detector\n",
    "y_train = y_train.astype(np.int8)\n",
    "y_test = y_test.astype(np.int8)\n",
    "y_train_2 = (y_train == 2)  # Changed '2' to 2\n",
    "y_test_2 = (y_test == 2)  # Changed '2' to 2\n",
    "\n",
    "# Train a logistic regression classifier\n",
    "clf = LogisticRegression(tol=0.1)\n",
    "clf.fit(x_train, y_train_2)\n",
    "example = clf.predict([some_digit])\n",
    "print(example)\n",
    "\n",
    "# Cross Validation\n",
    "a = cross_val_score(clf, x_train, y_train_2, cv=3, scoring=\"accuracy\")\n",
    "print(a.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e596e-b46f-414f-a41d-0deddfe12614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
